{
 "metadata": {
  "name": "",
  "signature": "sha256:271296dbd51b161d3f9c0b0f671ea5048dee19f34e26aaaf7bc82c82933af6d2"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Predicting Business Data for SMB\n",
      "================================"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%load_ext autoreload\n",
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "from sklearn import linear_model, cross_validation\n",
      "from smb_insights.schedules import *\n",
      "from smb_insights.service_point_selector import ServicePointSelector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# qh = load_quarter_hour_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#qh_d = load_quarter_hour_data_d()\n",
      "qh_d = load_quarter_hour_data_d_july()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# qh_r = load_quarter_hour_data_r()\n",
      "qh_r = load_quarter_hour_data_r_july()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# id = 0\n",
      "# plt.subplot(3,1,1)\n",
      "# plt.plot(qh_r.iloc[id][usage_columns])\n",
      "# plt.yticks(np.linspace(0,.2,5))\n",
      "# plt.tick_params(\\\n",
      "#     axis='x',          # changes apply to the x-axis\n",
      "#     which='both',      # both major and minor ticks are affected\n",
      "#     bottom='off',      # ticks along the bottom edge are off\n",
      "#     top='off',         # ticks along the top edge are off\n",
      "#     labelbottom='off') \n",
      "# plt.subplot(3,1,2)\n",
      "# plt.plot(qh_r.iloc[id+1][usage_columns])\n",
      "# plt.yticks(np.linspace(0,.2,5))\n",
      "# plt.tick_params(\\\n",
      "#     axis='x',          # changes apply to the x-axis\n",
      "#     which='both',      # both major and minor ticks are affected\n",
      "#     bottom='off',      # ticks along the bottom edge are off\n",
      "#     top='off',         # ticks along the top edge are off\n",
      "#     labelbottom='off') \n",
      "# util_id = qh_r.iloc[id]['util_service_point_id']\n",
      "# print util_id\n",
      "# plt.subplot(3,1,3)\n",
      "# plt.plot(qh_r[qh_r['util_service_point_id']==util_id][usage_columns].mean())\n",
      "# plt.yticks(np.linspace(0,.2,5))\n",
      "# plt.xticks(range(0, 96, 16), times_of_day()[::16])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# max_val = 0.75\n",
      "# id = 0\n",
      "# plt.subplot(3,1,1)\n",
      "# plt.plot(qh_d.iloc[id][usage_columns])\n",
      "# plt.yticks(np.linspace(0,max_val,5))\n",
      "# plt.tick_params(\\\n",
      "#     axis='x',          # changes apply to the x-axis\n",
      "#     which='both',      # both major and minor ticks are affected\n",
      "#     bottom='off',      # ticks along the bottom edge are off\n",
      "#     top='off',         # ticks along the top edge are off\n",
      "#     labelbottom='off') \n",
      "# plt.subplot(3,1,2)\n",
      "# plt.plot(qh_d.iloc[id+1][usage_columns])\n",
      "# plt.yticks(np.linspace(0,max_val,5))\n",
      "# plt.tick_params(\\\n",
      "#     axis='x',          # changes apply to the x-axis\n",
      "#     which='both',      # both major and minor ticks are affected\n",
      "#     bottom='off',      # ticks along the bottom edge are off\n",
      "#     top='off',         # ticks along the top edge are off\n",
      "#     labelbottom='off') \n",
      "# util_id = qh_d.iloc[id]['util_service_point_id']\n",
      "# print util_id\n",
      "# #plt.plot(qh_d.iloc[2][usage_columns])\n",
      "# #plt.savefig('foo_%s_%d.png' % (\"restaurant\", id))\n",
      "# plt.subplot(3,1,3)\n",
      "# plt.plot(qh_d[qh_d['util_service_point_id']==util_id][usage_columns].mean())\n",
      "# plt.yticks(np.linspace(0,max_val,5))\n",
      "# plt.xticks(range(0, 96, 16), times_of_day()[::16])\n",
      "\n",
      "# # single day/month graph\n",
      "# # id = 2000\n",
      "# # plt.plot(qh_d.iloc[id][usage_columns])\n",
      "# # plt.xticks(range(0, 96, 16), times_of_day()[::16])\n",
      "# # util_id = qh_d.iloc[id]['util_service_point_id']\n",
      "# # print util_id\n",
      "# # #plt.plot(qh_d.iloc[2][usage_columns])\n",
      "# # #plt.savefig('foo_%s_%d.png' % (\"restaurant\", id))\n",
      "# # plt.plot(qh_d[qh_d['util_service_point_id']==util_id][usage_columns].mean())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# #single day/month graph\n",
      "# id = 0\n",
      "# #plt.plot(qh_d.iloc[id][usage_columns])\n",
      "# #plt.xticks(range(0, 96, 16), times_of_day()[::16])\n",
      "# util_id = 1137741705 #qh_d.iloc[id]['util_service_point_id']\n",
      "# print util_id\n",
      "# #plt.plot(qh_d.iloc[2][usage_columns])\n",
      "# #plt.savefig('foo_%s_%d.png' % (\"restaurant\", id))\n",
      "# mean_data = qh_d[qh_d['util_service_point_id']==util_id][usage_columns].mean()\n",
      "# plt.plot(mean_data)\n",
      "\n",
      "# switch_index = 1\n",
      "# switch_index_1 = 33\n",
      "# switch_index_2 = 69\n",
      "# plt.axvline(switch_index, color='red')\n",
      "# plt.axvline(switch_index_1, color='red')\n",
      "# plt.axvline(switch_index_2, color='red')\n",
      "# #plt.text(switch_index, day_values.min() + (day_values.max() - \n",
      "# #                                        day_values.min())*0.05, ' Closed', color='red',\n",
      "# #                                        verticalalignment='baseline', size='larger', weight='bold')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# #single day/month graph\n",
      "# id = 0\n",
      "# #plt.plot(qh_d.iloc[id][usage_columns])\n",
      "# #plt.xticks(range(0, 96, 16), times_of_day()[::16])\n",
      "# util_id = 1137811605 #qh_d.iloc[id]['util_service_point_id']\n",
      "# print util_id\n",
      "# #plt.plot(qh_d.iloc[2][usage_columns])\n",
      "# #plt.savefig('foo_%s_%d.png' % (\"restaurant\", id))\n",
      "# mean_data = qh_d[qh_d['util_service_point_id']==util_id][usage_columns].mean()\n",
      "# plt.plot(mean_data)\n",
      "\n",
      "# switch_index = 1\n",
      "# switch_index_1 = 32\n",
      "# switch_index_2 = 69\n",
      "# plt.xticks(range(0, 96, 16), times_of_day()[::16])\n",
      "# plt.axvline(switch_index, color='red')\n",
      "# plt.axvline(switch_index_1, color='red')\n",
      "# plt.axvline(switch_index_2, color='red')\n",
      "# #plt.text(switch_index, day_values.min() + (day_values.max() - \n",
      "# #                                        day_values.min())*0.05, ' Closed', color='red',\n",
      "# #                                        verticalalignment='baseline', size='larger', weight='bold')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# # state graph for restaurants \n",
      "\n",
      "# util_id = 8565778105 #qh_d.iloc[id]['util_service_point_id']\n",
      "# print util_id\n",
      "# mean_data = qh_r[qh_r['util_service_point_id']==util_id][usage_columns].mean()\n",
      "# plt.plot(mean_data)\n",
      "\n",
      "# switch_index = 1\n",
      "# switch_index_1 = 47\n",
      "# switch_index_3 = 89\n",
      "# plt.xticks(range(0, 96, 16), times_of_day()[::16])\n",
      "# plt.axvline(switch_index, color='red')\n",
      "# plt.axvline(switch_index_1, color='red')\n",
      "# plt.axvline(switch_index_2, color='red')\n",
      "# plt.axvline(switch_index_3, color='red')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# #single day/month graph\n",
      "# id = 0\n",
      "# #plt.plot(qh_d.iloc[id][usage_columns])\n",
      "# #plt.xticks(range(0, 96, 16), times_of_day()[::16])\n",
      "# util_id = qh_d.iloc[id]['util_service_point_id']\n",
      "# print '1137741705'\n",
      "# #plt.plot(qh_d.iloc[2][usage_columns])\n",
      "# #plt.savefig('foo_%s_%d.png' % (\"restaurant\", id))\n",
      "# mean_data = qh_d[qh_d['util_service_point_id']==util_id][usage_columns].mean()\n",
      "# plt.plot(mean_data)\n",
      "\n",
      "# switch_index = 1\n",
      "# switch_index_1 = 33\n",
      "# switch_index_2 = 69\n",
      "# plt.axvline(switch_index, color='red')\n",
      "# plt.axvline(switch_index_1, color='red')\n",
      "# plt.axvline(switch_index_2, color='red')\n",
      "# #plt.text(switch_index, day_values.min() + (day_values.max() - \n",
      "# #                                        day_values.min())*0.05, ' Closed', color='red',\n",
      "# #                                        verticalalignment='baseline', size='larger', weight='bold')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in restaurant probabilities\n",
      "# restaurantP = pd.read_csv(\"data/restaurantProbability.csv\", sep=\",\")\n",
      "# july\n",
      "restaurantP = pd.read_csv(\"data/JulRestaurantProbability.csv\", sep=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in dentist probabilities\n",
      "# dentistP = pd.read_csv(\"data/dentistProbability.csv\", sep=\",\")\n",
      "# july\n",
      "dentistP = pd.read_csv(\"data/JulDentistProbability.csv\", sep=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in restaurant labels\n",
      "# restaurantLabels = pd.read_csv(\"data/restaurantLabels.csv\", sep=\",\")\n",
      "# july\n",
      "restaurantLabels = pd.read_csv(\"data/JulRestaurantLabels.csv\", sep=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in dentist labels\n",
      "# dentistLabels = pd.read_csv(\"data/dentistLabels.csv\", sep=\",\")\n",
      "# july\n",
      "dentistLabels = pd.read_csv(\"data/JulDentistLabels.csv\", sep=\",\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read in business types\n",
      "types = pd.read_csv(\"data/pge_smb_naics.tsv\", sep=\"\\t\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Merging AMI and types datasets\n",
      "pre_merged_d = pd.merge(types, qh_d, on=\"util_service_point_id\")\n",
      "pre_merged_r = pd.merge(types, qh_r, on=\"util_service_point_id\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# weekend cell\n",
      "pre_merged_d['weekday'] = pd.DatetimeIndex(pre_merged_d['date_value']).weekday\n",
      "pre_merged_r['weekday'] = pd.DatetimeIndex(pre_merged_r['date_value']).weekday\n",
      "print pre_merged_d.columns[-5:]\n",
      "\n",
      "# split out weekends\n",
      "pre_merged_d_weekday = pre_merged_d[pre_merged_d['weekday'] <= 4]\n",
      "pre_merged_d_weekend = pre_merged_d[pre_merged_d['weekday'] >= 5]\n",
      "\n",
      "pre_merged_r_weekday = pre_merged_r[pre_merged_r['weekday'] <= 4]\n",
      "pre_merged_r_weekend = pre_merged_r[pre_merged_r['weekday'] >= 5]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'usage_value_2300', u'usage_value_2315', u'usage_value_2330', u'usage_value_2345', u'weekday'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Groupby a given business id to return one row per business\n",
      "merged_d_group = pre_merged_d.groupby(['util_service_point_id'], as_index=False)\n",
      "merged_r_group = pre_merged_r.groupby(['util_service_point_id'], as_index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# weekend cell\n",
      "# Groupby splits for weekends and weekdays\n",
      "merged_d_group_day = pre_merged_d_weekday.groupby(['util_service_point_id'], as_index=False)\n",
      "merged_d_group_end = pre_merged_d_weekend.groupby(['util_service_point_id'], as_index=False)\n",
      "\n",
      "merged_r_group_day = pre_merged_r_weekday.groupby(['util_service_point_id'], as_index=False)\n",
      "merged_r_group_end = pre_merged_r_weekend.groupby(['util_service_point_id'], as_index=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "merged_d_series = merged_d_group.mean()\n",
      "merged_r_series = merged_r_group.mean()\n",
      "# def get_series(average):\n",
      "#     if average == True:\n",
      "#         # Monthly average: take the average of all readings for a given business\n",
      "#         merged_d_series = merged_d_group.mean()\n",
      "#         merged_r_series = merged_r_group.mean()\n",
      "#     else:\n",
      "#         # Single day: use a single reading for a given business\n",
      "#         merged_d_series = merged_d_group.head(1)\n",
      "#         merged_r_series = merged_r_group.head(1)\n",
      "#     return merged_d_series, merged_r_series_day\n",
      "\n",
      "# # Output one row per business, either choose a single day or average over all days\n",
      "# average = True\n",
      "# (merged_d_series, merged_r_series) = get_series(average)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# weekend cell\n",
      "# take the average of weekend/day readings for a given business\n",
      "merged_d_series_day = merged_d_group_day.mean()\n",
      "merged_d_series_end = merged_d_group_end.mean()\n",
      "\n",
      "merged_r_series_day = merged_r_group_day.mean()\n",
      "merged_r_series_end = merged_r_group_end.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# id = 9\n",
      "# plt.plot(qh_r.iloc[id][usage_columns])\n",
      "# print qh_r.iloc[id]['util_service_point_id']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Converting series back into dataframe\n",
      "merged_d = pd.DataFrame(merged_d_series)\n",
      "merged_r = pd.DataFrame(merged_r_series)\n",
      "\n",
      "# Converting series back into dataframe, split for weekday/end\n",
      "merged_d_day = pd.DataFrame(merged_d_series_day)\n",
      "merged_d_end = pd.DataFrame(merged_d_series_end)\n",
      "\n",
      "merged_r_day = pd.DataFrame(merged_r_series_day)\n",
      "merged_r_end = pd.DataFrame(merged_r_series_end)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Add name4 column\n",
      "merged_d[\"name4\"] = \"Offices of Dentists\"\n",
      "merged_r[\"name4\"] = \"Food Services and Drinking Places\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get all dentists and restaurants\n",
      "dentists = merged_d[merged_d[\"name4\"]==\"Offices of Dentists\"]\n",
      "restaurants = merged_r[merged_r[\"name4\"]==\"Food Services and Drinking Places\"]\n",
      "dentists = merged_d.dropna()\n",
      "restaurants = merged_r.dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# weekend cell\n",
      "# get all dentists and restaurants\n",
      "merged_d_day[\"name4\"] = \"Offices of Dentists\"\n",
      "merged_d_end[\"name4\"] = \"Offices of Dentists\"\n",
      "merged_r_day[\"name4\"] = \"Food Services and Drinking Places\"\n",
      "merged_r_end[\"name4\"] = \"Food Services and Drinking Places\"\n",
      "\n",
      "dentists_day = merged_d_day.dropna()\n",
      "dentists_end = merged_d_end.dropna()\n",
      "restaurants_day = merged_r_day.dropna()\n",
      "restaurants_end = merged_r_end.dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# weekend cell\n",
      "# weekday merge into giant feature table\n",
      "weekend_and_weekday_d = pd.merge(dentists_day, dentists_end, suffixes=[\"_day\", \"_end\"], on=\"util_service_point_id\")\n",
      "weekend_and_weekday_r = pd.merge(restaurants_day, restaurants_end, suffixes=[\"_day\", \"_end\"], on=\"util_service_point_id\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Merge probability column in, restaurants\n",
      "merged_with_restaurants = restaurants.merge(restaurantP, on='util_service_point_id', how=\"inner\")\n",
      "merged_with_restaurants = merged_with_restaurants.merge(restaurantLabels, on='util_service_point_id', how=\"inner\")\n",
      "print merged_with_restaurants.columns[-10:]\n",
      "merged_with_restaurants = merged_with_restaurants.merge(weekend_and_weekday_r, on='util_service_point_id', how=\"inner\")\n",
      "print merged_with_restaurants.columns[-10:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'usage_value_2230', u'usage_value_2245', u'usage_value_2300', u'usage_value_2315', u'usage_value_2330', u'usage_value_2345', u'weekday', u'name4', u'probabilityDentist', u'dentist'], dtype='object')\n",
        "Index([u'usage_value_2200_end', u'usage_value_2215_end', u'usage_value_2230_end', u'usage_value_2245_end', u'usage_value_2300_end', u'usage_value_2315_end', u'usage_value_2330_end', u'usage_value_2345_end', u'weekday_end', u'name4_end'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Merge probability column in, dentists\n",
      "merged_with_dentists = dentists.merge(dentistP, on='util_service_point_id', how=\"inner\")\n",
      "merged_with_dentists = merged_with_dentists.merge(dentistLabels, on='util_service_point_id', how=\"inner\")\n",
      "merged_with_dentists = merged_with_dentists.merge(weekend_and_weekday_d, on='util_service_point_id', how='inner')\n",
      "print merged_with_dentists.columns[-10:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'usage_value_2200_end', u'usage_value_2215_end', u'usage_value_2230_end', u'usage_value_2245_end', u'usage_value_2300_end', u'usage_value_2315_end', u'usage_value_2330_end', u'usage_value_2345_end', u'weekday_end', u'name4_end'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Concat dentists and restaurants\n",
      "min_len = min(len(merged_with_dentists), len(merged_with_restaurants))\n",
      "smb = pd.concat([merged_with_dentists[:min_len], merged_with_restaurants[:min_len]])\n",
      "smb.index = range(len(smb))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get all features\n",
      "smb.fillna(0.0, inplace=True)\n",
      "#print smb.columns[19:115]\n",
      "#print smb.columns[137:233]\n",
      "print smb.columns[253:350]\n",
      "features = smb[list(smb.columns[19:115]) + ['dentist', 'probabilityDentist', 'name4']\n",
      "               + list(smb.columns[137:233]) + list(smb.columns[253:349])]\n",
      "#print features.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Index([u'usage_value_000_end', u'usage_value_015_end', u'usage_value_030_end', u'usage_value_045_end', u'usage_value_100_end', u'usage_value_115_end', u'usage_value_130_end', u'usage_value_145_end', u'usage_value_200_end', u'usage_value_215_end', u'usage_value_230_end', u'usage_value_245_end', u'usage_value_300_end', u'usage_value_315_end', u'usage_value_330_end', u'usage_value_345_end', u'usage_value_400_end', u'usage_value_415_end', u'usage_value_430_end', u'usage_value_445_end', u'usage_value_500_end', u'usage_value_515_end', u'usage_value_530_end', u'usage_value_545_end', u'usage_value_600_end', u'usage_value_615_end', u'usage_value_630_end', u'usage_value_645_end', u'usage_value_700_end', u'usage_value_715_end', u'usage_value_730_end', u'usage_value_745_end', u'usage_value_800_end', u'usage_value_815_end', u'usage_value_830_end', u'usage_value_845_end', u'usage_value_900_end', u'usage_value_915_end', u'usage_value_930_end', u'usage_value_945_end', u'usage_value_1000_end', u'usage_value_1015_end', u'usage_value_1030_end', u'usage_value_1045_end', u'usage_value_1100_end', u'usage_value_1115_end', u'usage_value_1130_end', u'usage_value_1145_end', u'usage_value_1200_end', u'usage_value_1215_end', u'usage_value_1230_end', u'usage_value_1245_end', u'usage_value_1300_end', u'usage_value_1315_end', u'usage_value_1330_end', u'usage_value_1345_end', u'usage_value_1400_end', u'usage_value_1415_end', u'usage_value_1430_end', u'usage_value_1445_end', u'usage_value_1500_end', u'usage_value_1515_end', u'usage_value_1530_end', u'usage_value_1545_end', u'usage_value_1600_end', u'usage_value_1615_end', u'usage_value_1630_end', u'usage_value_1645_end', u'usage_value_1700_end', u'usage_value_1715_end', u'usage_value_1730_end', u'usage_value_1745_end', u'usage_value_1800_end', u'usage_value_1815_end', u'usage_value_1830_end', u'usage_value_1845_end', u'usage_value_1900_end', u'usage_value_1915_end', u'usage_value_1930_end', u'usage_value_1945_end', u'usage_value_2000_end', u'usage_value_2015_end', u'usage_value_2030_end', u'usage_value_2045_end', u'usage_value_2100_end', u'usage_value_2115_end', u'usage_value_2130_end', u'usage_value_2145_end', u'usage_value_2200_end', u'usage_value_2215_end', u'usage_value_2230_end', u'usage_value_2245_end', u'usage_value_2300_end', u'usage_value_2315_end', u'usage_value_2330_end', u'usage_value_2345_end', u'weekday_end'], dtype='object')\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# monthly\n",
      "# features_d = dentists.iloc[:,19:115]\n",
      "# features_r = restaurants.iloc[:,19:115]\n",
      "\n",
      "# single day\n",
      "# features_d = dentists.iloc[:,25:122]\n",
      "# features_r = restaurants.iloc[:,25:122]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Shuffle features\n",
      "np.random.seed(0)\n",
      "features = features.reindex(np.random.permutation(features.index)) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define usage column feature sets\n",
      "overall_usage_columns = [u'usage_value_000', u'usage_value_015', u'usage_value_030', u'usage_value_045', u'usage_value_100', u'usage_value_115', u'usage_value_130', u'usage_value_145', u'usage_value_200', u'usage_value_215', u'usage_value_230', u'usage_value_245', u'usage_value_300', u'usage_value_315', u'usage_value_330', u'usage_value_345', u'usage_value_400', u'usage_value_415', u'usage_value_430', u'usage_value_445', u'usage_value_500', u'usage_value_515', u'usage_value_530', u'usage_value_545', u'usage_value_600', u'usage_value_615', u'usage_value_630', u'usage_value_645', u'usage_value_700', u'usage_value_715', u'usage_value_730', u'usage_value_745', u'usage_value_800', u'usage_value_815', u'usage_value_830', u'usage_value_845', u'usage_value_900', u'usage_value_915', u'usage_value_930', u'usage_value_945', u'usage_value_1000', u'usage_value_1015', u'usage_value_1030', u'usage_value_1045', u'usage_value_1100', u'usage_value_1115', u'usage_value_1130', u'usage_value_1145', u'usage_value_1200', u'usage_value_1215', u'usage_value_1230', u'usage_value_1245', u'usage_value_1300', u'usage_value_1315', u'usage_value_1330', u'usage_value_1345', u'usage_value_1400', u'usage_value_1415', u'usage_value_1430', u'usage_value_1445', u'usage_value_1500', u'usage_value_1515', u'usage_value_1530', u'usage_value_1545', u'usage_value_1600', u'usage_value_1615', u'usage_value_1630', u'usage_value_1645', u'usage_value_1700', u'usage_value_1715', u'usage_value_1730', u'usage_value_1745', u'usage_value_1800', u'usage_value_1815', u'usage_value_1830', u'usage_value_1845', u'usage_value_1900', u'usage_value_1915', u'usage_value_1930', u'usage_value_1945', u'usage_value_2000', u'usage_value_2015', u'usage_value_2030', u'usage_value_2045', u'usage_value_2100', u'usage_value_2115', u'usage_value_2130', u'usage_value_2145', u'usage_value_2200', u'usage_value_2215', u'usage_value_2230', u'usage_value_2245', u'usage_value_2300', u'usage_value_2315', u'usage_value_2330', u'usage_value_2345']\n",
      "weekday_usage_columns = [u'usage_value_000_day', u'usage_value_015_day', u'usage_value_030_day', u'usage_value_045_day', u'usage_value_100_day', u'usage_value_115_day', u'usage_value_130_day', u'usage_value_145_day', u'usage_value_200_day', u'usage_value_215_day', u'usage_value_230_day', u'usage_value_245_day', u'usage_value_300_day', u'usage_value_315_day', u'usage_value_330_day', u'usage_value_345_day', u'usage_value_400_day', u'usage_value_415_day', u'usage_value_430_day', u'usage_value_445_day', u'usage_value_500_day', u'usage_value_515_day', u'usage_value_530_day', u'usage_value_545_day', u'usage_value_600_day', u'usage_value_615_day', u'usage_value_630_day', u'usage_value_645_day', u'usage_value_700_day', u'usage_value_715_day', u'usage_value_730_day', u'usage_value_745_day', u'usage_value_800_day', u'usage_value_815_day', u'usage_value_830_day', u'usage_value_845_day', u'usage_value_900_day', u'usage_value_915_day', u'usage_value_930_day', u'usage_value_945_day', u'usage_value_1000_day', u'usage_value_1015_day', u'usage_value_1030_day', u'usage_value_1045_day', u'usage_value_1100_day', u'usage_value_1115_day', u'usage_value_1130_day', u'usage_value_1145_day', u'usage_value_1200_day', u'usage_value_1215_day', u'usage_value_1230_day', u'usage_value_1245_day', u'usage_value_1300_day', u'usage_value_1315_day', u'usage_value_1330_day', u'usage_value_1345_day', u'usage_value_1400_day', u'usage_value_1415_day', u'usage_value_1430_day', u'usage_value_1445_day', u'usage_value_1500_day', u'usage_value_1515_day', u'usage_value_1530_day', u'usage_value_1545_day', u'usage_value_1600_day', u'usage_value_1615_day', u'usage_value_1630_day', u'usage_value_1645_day', u'usage_value_1700_day', u'usage_value_1715_day', u'usage_value_1730_day', u'usage_value_1745_day', u'usage_value_1800_day', u'usage_value_1815_day', u'usage_value_1830_day', u'usage_value_1845_day', u'usage_value_1900_day', u'usage_value_1915_day', u'usage_value_1930_day', u'usage_value_1945_day', u'usage_value_2000_day', u'usage_value_2015_day', u'usage_value_2030_day', u'usage_value_2045_day', u'usage_value_2100_day', u'usage_value_2115_day', u'usage_value_2130_day', u'usage_value_2145_day', u'usage_value_2200_day', u'usage_value_2215_day', u'usage_value_2230_day', u'usage_value_2245_day', u'usage_value_2300_day', u'usage_value_2315_day', u'usage_value_2330_day', u'usage_value_2345_day']\n",
      "weekend_usage_columns = [u'usage_value_000_end', u'usage_value_015_end', u'usage_value_030_end', u'usage_value_045_end', u'usage_value_100_end', u'usage_value_115_end', u'usage_value_130_end', u'usage_value_145_end', u'usage_value_200_end', u'usage_value_215_end', u'usage_value_230_end', u'usage_value_245_end', u'usage_value_300_end', u'usage_value_315_end', u'usage_value_330_end', u'usage_value_345_end', u'usage_value_400_end', u'usage_value_415_end', u'usage_value_430_end', u'usage_value_445_end', u'usage_value_500_end', u'usage_value_515_end', u'usage_value_530_end', u'usage_value_545_end', u'usage_value_600_end', u'usage_value_615_end', u'usage_value_630_end', u'usage_value_645_end', u'usage_value_700_end', u'usage_value_715_end', u'usage_value_730_end', u'usage_value_745_end', u'usage_value_800_end', u'usage_value_815_end', u'usage_value_830_end', u'usage_value_845_end', u'usage_value_900_end', u'usage_value_915_end', u'usage_value_930_end', u'usage_value_945_end', u'usage_value_1000_end', u'usage_value_1015_end', u'usage_value_1030_end', u'usage_value_1045_end', u'usage_value_1100_end', u'usage_value_1115_end', u'usage_value_1130_end', u'usage_value_1145_end', u'usage_value_1200_end', u'usage_value_1215_end', u'usage_value_1230_end', u'usage_value_1245_end', u'usage_value_1300_end', u'usage_value_1315_end', u'usage_value_1330_end', u'usage_value_1345_end', u'usage_value_1400_end', u'usage_value_1415_end', u'usage_value_1430_end', u'usage_value_1445_end', u'usage_value_1500_end', u'usage_value_1515_end', u'usage_value_1530_end', u'usage_value_1545_end', u'usage_value_1600_end', u'usage_value_1615_end', u'usage_value_1630_end', u'usage_value_1645_end', u'usage_value_1700_end', u'usage_value_1715_end', u'usage_value_1730_end', u'usage_value_1745_end', u'usage_value_1800_end', u'usage_value_1815_end', u'usage_value_1830_end', u'usage_value_1845_end', u'usage_value_1900_end', u'usage_value_1915_end', u'usage_value_1930_end', u'usage_value_1945_end', u'usage_value_2000_end', u'usage_value_2015_end', u'usage_value_2030_end', u'usage_value_2045_end', u'usage_value_2100_end', u'usage_value_2115_end', u'usage_value_2130_end', u'usage_value_2145_end', u'usage_value_2200_end', u'usage_value_2215_end', u'usage_value_2230_end', u'usage_value_2245_end', u'usage_value_2300_end', u'usage_value_2315_end', u'usage_value_2330_end', u'usage_value_2345_end']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define regression steps\n",
      "def run_regression(features, seed=0, n_folds=10, standardize_feats=False):\n",
      "    num_correct = 0\n",
      "    for train_index, test_index in cross_validation.KFold(n=len(features), n_folds=n_folds, shuffle=True, random_state=seed):\n",
      "        # features\n",
      "        train_features = features.iloc[list(train_index)]\n",
      "        test_features = features.iloc[list(test_index)]\n",
      "\n",
      "        # labels\n",
      "        train_labels = train_features['name4']\n",
      "        test_labels = test_features['name4']\n",
      "\n",
      "        # drop labels from feature set\n",
      "        train_features.drop('name4', axis=1, inplace=True)\n",
      "        test_features.drop('name4', axis=1, inplace=True)\n",
      "\n",
      "        # standardize\n",
      "        if standardize_feats:\n",
      "            train_mean = train_features.mean()\n",
      "            train_mean_zero = train_features - train_mean\n",
      "            train_std = train_mean_zero.std()\n",
      "            train_std_one = train_mean_zero / train_std\n",
      "            train_features = train_std_one\n",
      "            \n",
      "            test_mean_zero = test_features - train_mean\n",
      "            test_std_one = test_mean_zero / train_std\n",
      "            test_features = test_std_one\n",
      "        \n",
      "        # fit \n",
      "        lr = linear_model.LogisticRegression()\n",
      "        lr.fit(train_features, train_labels)\n",
      "\n",
      "        # predict\n",
      "        predictions = lr.predict(test_features)\n",
      "\n",
      "        # score\n",
      "        correct = predictions==test_labels\n",
      "        num_correct += sum(correct)\n",
      "    \n",
      "    accuracy = num_correct/float(len(features))\n",
      "    print accuracy\n",
      "    return accuracy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define normalization steps\n",
      "def do_normalization(normalize, features):\n",
      "    usage_features = features[overall_usage_columns]\n",
      "    sum_column = usage_features.sum(axis=1)\n",
      "    usage_features = usage_features.div(sum_column,axis='index')\n",
      "    usage_features.fillna(0.0,inplace=True)\n",
      "    if normalize:\n",
      "        features[overall_usage_columns] = usage_features\n",
      "    features['usage_sum'] = sum_column\n",
      "    return features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Define features sets \n",
      "def pick_features(features, feature_set):\n",
      "    if feature_set == 'just_usage':\n",
      "        return features[overall_usage_columns + ['name4']]\n",
      "    elif feature_set == 'usage_sum':\n",
      "        return features[overall_usage_columns + ['usage_sum', 'name4']]\n",
      "    elif feature_set == 'just_prob':\n",
      "        return features[['probabilityDentist', 'name4']]\n",
      "    elif feature_set == 'usage_prob':\n",
      "        return features[overall_usage_columns + ['probabilityDentist', 'name4']]\n",
      "    elif feature_set == 'usage_label':\n",
      "        return features[overall_usage_columns + ['dentist', 'name4']]\n",
      "    elif feature_set == 'usage_prob_label':\n",
      "        return features[overall_usage_columns + ['probabilityDentist', 'dentist', 'name4']]\n",
      "    elif feature_set == 'just_usage_w':\n",
      "        return features[weekday_usage_columns + weekend_usage_columns + ['name4']]\n",
      "    elif feature_set == 'usage_w_prob':\n",
      "        return features[weekday_usage_columns + weekend_usage_columns + ['probabilityDentist', 'name4']]\n",
      "    elif feature_set == 'usage_w_label':\n",
      "        return features[weekday_usage_columns + weekend_usage_columns + ['dentist', 'name4']]\n",
      "    elif feature_set == 'usage_w_prob_label':\n",
      "        return features[weekday_usage_columns + weekend_usage_columns + ['probabilityDentist', 'dentist', 'name4']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feature_sets = ['just_usage', 'usage_sum', 'just_prob', 'usage_prob', 'usage_label', 'usage_prob_label', \n",
      "                'just_usage_w', 'usage_w_prob', 'usage_w_label', 'usage_w_prob_label']\n",
      "\n",
      "normalize_usage_values = [True, False]\n",
      "standardize_values = [True, False]\n",
      "\n",
      "# Run experiments\n",
      "accuracies = []\n",
      "names = []\n",
      "seed = 0\n",
      "n_folds = 10\n",
      "for standardize in standardize_values:\n",
      "    for normalize_usage in normalize_usage_values:\n",
      "        experiment_features_normalization = features.copy()\n",
      "        experiment_features_normalization = do_normalization(normalize_usage, experiment_features_normalization)\n",
      "        for feature_set in feature_sets:\n",
      "            experiment_features = experiment_features_normalization.copy()\n",
      "            experiment_features = pick_features(experiment_features, feature_set)\n",
      "\n",
      "            print \"Feature set: %s\" % feature_set\n",
      "            print \"Standardize =\", standardize\n",
      "            print \"Normalization =\",normalize_usage\n",
      "            names.append(\"%s_%s_%s\" % (feature_set, normalize, standardize))\n",
      "            accuracies.append(run_regression(experiment_features, seed, n_folds, standardize))\n",
      "            #print '\\n'\n",
      "\n",
      "plt.bar(range(len(accuracies)), accuracies)\n",
      "plt.title(\"Accuracy Histogram\")\n",
      "plt.xlabel(\"Feature Set\")\n",
      "plt.ylabel(\"Accuracy\")\n",
      "plt.xticks(range(len(accuracies)), names, rotation='vertical') \n",
      "plt.ylim([.75,1])\n",
      "plt.show()\n",
      "\n",
      "# print accuracies\n",
      "\n",
      "# # interesting accuracies\n",
      "# print len(accuracies)\n",
      "# print len(set(accuracies))\n",
      "# interesting_accuracies = list(set(accuracies))\n",
      "# plt.bar(range(len(interesting_accuracies)), interesting_accuracies)\n",
      "# plt.title(\"Accuracy Histogram\")\n",
      "# plt.xlabel(\"Feature Set\")\n",
      "# plt.ylabel(\"Accuracy\")\n",
      "# plt.xticks(range(len(interesting_accuracies)), names, rotation='vertical') \n",
      "# plt.ylim([.75,1])\n",
      "# plt.show()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Feature set: just_usage\n",
        "Standardize = True\n",
        "Normalization = True\n",
        "0.878401360544"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_sum\n",
        "Standardize = True\n",
        "Normalization = True\n",
        "0.882653061224"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: just_prob\n",
        "Standardize = True\n",
        "Normalization = True\n",
        "0.768707482993"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_prob\n",
        "Standardize = True\n",
        "Normalization = True\n",
        "0.877551020408"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_label\n",
        "Standardize = True\n",
        "Normalization = True\n",
        "0.876700680272"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_prob_label\n",
        "Standardize = True\n",
        "Normalization = True\n",
        "0.878401360544"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: just_usage_w\n",
        "Standardize = True\n",
        "Normalization = True\n",
        "0.903911564626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_w_prob\n",
        "Standardize = True\n",
        "Normalization = True\n",
        "0.903911564626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_w_label\n",
        "Standardize = True\n",
        "Normalization = True\n",
        "0.903911564626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_w_prob_label\n",
        "Standardize = True\n",
        "Normalization = True\n",
        "0.903911564626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: just_usage\n",
        "Standardize = True\n",
        "Normalization = False\n",
        "0.878401360544"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_sum\n",
        "Standardize = True\n",
        "Normalization = False\n",
        "0.878401360544"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: just_prob\n",
        "Standardize = True\n",
        "Normalization = False\n",
        "0.768707482993"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_prob\n",
        "Standardize = True\n",
        "Normalization = False\n",
        "0.882653061224"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_label\n",
        "Standardize = True\n",
        "Normalization = False\n",
        "0.882653061224"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_prob_label\n",
        "Standardize = True\n",
        "Normalization = False\n",
        "0.882653061224"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: just_usage_w\n",
        "Standardize = True\n",
        "Normalization = False\n",
        "0.903911564626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_w_prob\n",
        "Standardize = True\n",
        "Normalization = False\n",
        "0.903911564626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_w_label\n",
        "Standardize = True\n",
        "Normalization = False\n",
        "0.903911564626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_w_prob_label\n",
        "Standardize = True\n",
        "Normalization = False\n",
        "0.903911564626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: just_usage\n",
        "Standardize = False\n",
        "Normalization = True\n",
        "0.87925170068"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_sum\n",
        "Standardize = False\n",
        "Normalization = True\n",
        "0.799319727891"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: just_prob\n",
        "Standardize = False\n",
        "Normalization = True\n",
        "0.768707482993"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_prob\n",
        "Standardize = False\n",
        "Normalization = True\n",
        "0.772108843537"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_label\n",
        "Standardize = False\n",
        "Normalization = True\n",
        "0.771258503401"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_prob_label\n",
        "Standardize = False\n",
        "Normalization = True\n",
        "0.770408163265"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: just_usage_w\n",
        "Standardize = False\n",
        "Normalization = True\n",
        "0.902210884354"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_w_prob\n",
        "Standardize = False\n",
        "Normalization = True\n",
        "0.90306122449"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_w_label\n",
        "Standardize = False\n",
        "Normalization = True\n",
        "0.90306122449"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Feature set: usage_w_prob_label\n",
        "Standardize = False\n",
        "Normalization = True\n",
        "0.90306122449"
       ]
      }
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----\n",
      "# Example Businesses\n",
      "\n",
      "## Day business\n",
      "Here's an example of a day-business, one which has it's highest usage during day-time hours"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "day_business = get_day_values(qh, 1154546705)\n",
      "plot_day(day_business)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Night business\n",
      "Here's an example of a night-business, one with it's lowest usage during the day, with spikes in the evening and early morning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "night_business = get_day_values(qh, 7170590801)\n",
      "plot_day(night_business)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----\n",
      "# Business Browser\n",
      "Select a business below, given by the util service point ID "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sp_selector = ServicePointSelector(qh)\n",
      "sp_selector.run_selector()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}